{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "# import kaggledatasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imageset(Dataset):\n",
    "    def __init__(self, dir_path, shape):\n",
    "        self.dir_path = dir_path\n",
    "        self.img_shape = shape\n",
    "        self.img_list = self.read_files(self.dir_path)\n",
    "\n",
    "    def read_files(self, dir_path):\n",
    "        file_list = os.listdir(dir_path)\n",
    "        return file_list\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return torch.Tensor(plt.imread(self.dir_path+self.img_list[index]))\n",
    "#         return plt.imread(self.dir_path+self.img_list[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Imageset('./monet_jpg/', [256,256])\n",
    "y = Imageset('./photo_jpg/', [256,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monetset = Imageset('./monet_jpg/', [256,256])\n",
    "photoset = Imageset('./photo_jpg/', [256,256])\n",
    "\n",
    "\n",
    "monet_loader = DataLoader(dataset = monetset,\n",
    "                           batch_size=1,\n",
    "                           shuffle=True, \n",
    "                           num_workers=0)\n",
    "\n",
    "photo_loader = DataLoader(dataset = photoset,\n",
    "                           batch_size=1,\n",
    "                           shuffle=True, \n",
    "                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_noins(in_dim, out_dim, size):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size=size, stride=2, padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(in_dim, out_dim, size):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size=size, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(out_dim),\n",
    "        nn.LeakyReLU(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(in_dim, out_dim, size):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size=size, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(out_dim),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_drop(in_dim, out_dim, size):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size=size, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(out_dim),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        ## init Unet\n",
    "        \n",
    "        self.down_1 = downsample_noins(3,64,4)\n",
    "        self.down_2 = downsample(64,128,4)\n",
    "        self.down_3 = downsample(128,256,4)\n",
    "        self.down_4 = downsample(256,512,4)\n",
    "        self.down_5 = downsample(512,512,4)\n",
    "        self.down_6 = downsample(512,512,4)\n",
    "        self.down_7 = downsample(512,512,4)\n",
    "        self.down_8 = downsample(512,512,3)\n",
    "\n",
    "        self.up_1 = upsample_drop(512,512,4)\n",
    "        self.up_2 = upsample_drop(1024,512,4)\n",
    "        self.up_3 = upsample_drop(1024,512,4)\n",
    "        self.up_4 = upsample(1024,256,4)\n",
    "        self.up_5 = upsample(512,128,4)\n",
    "        self.up_6 = upsample(256,64,4)\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, out_dim, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # [b,256,256,3] -> [b,3,256,256]\n",
    "        input = input.permute(0,3,1,2)\n",
    "\n",
    "        d_1 = self.down_1(input) # [b,64,128,128]\n",
    "        d_2 = self.down_2(d_1) # [b,128,64,64]\n",
    "        d_3 = self.down_3(d_2) # [b, 256,32,32]\n",
    "        d_4 = self.down_4(d_3) # [b,512,16,16]\n",
    "        d_5 = self.down_5(d_4) # [b,512,8,8]\n",
    "        d_6 = self.down_6(d_5) # [b,512,4,4]\n",
    "        d_7 = self.down_7(d_6) # [b,512,2,2]\n",
    "        \n",
    "        u_1 = self.up_1(d_7) # [b,512,4,4]\n",
    "        concat_1 = torch.cat([u_1, d_6], dim=1) # [b,1024,4,4]\n",
    "        u_2 = self.up_2(concat_1) # [b,1024,8,8]\n",
    "        concat_2 = torch.cat([u_2, d_5], dim=1) # [b,1024,8,8]\n",
    "        u_3 = self.up_3(concat_2) # [b,1024,16,16]\n",
    "        concat_3 = torch.cat([u_3, d_4], dim=1) # [b,1024,16,16]\n",
    "        u_4 = self.up_4(concat_3)\n",
    "        concat_4 = torch.cat([u_4, d_3], dim=1) # [b,512,32,32]\n",
    "        u_5 = self.up_5(concat_4)\n",
    "        concat_5 = torch.cat([u_5, d_2], dim=1) # [b,256,64,64]\n",
    "        u_6 = self.up_6(concat_5)\n",
    "        concat_6 = torch.cat([u_6, d_1], dim=1) # [b,128,128,128]\n",
    "        out = self.last(concat_6)\n",
    "        out = out.permute(0,2,3,1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        act_fn = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        \n",
    "        ## init Unet\n",
    "        self.down_1 = downsample_noins(3,64,4)\n",
    "        self.down_2 = downsample(64,128,4)\n",
    "        self.down_3 = downsample(128,256,4)\n",
    "        self.down_4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=2),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # [b,256,256,3] -> [b,3,256,256]\n",
    "        input = input.permute(0,3,1,2)\n",
    "\n",
    "        d_1 = self.down_1(input) # [b,64,128,128]\n",
    "        d_2 = self.down_2(d_1) # [b,128,64,64]\n",
    "        d_3 = self.down_3(d_2) # [b, 256,32,32]\n",
    "        d_4 = self.down_4(d_3) # [b, 512,33,33]\n",
    "        out = self.last(d_4) # [b, 1,30,30]\n",
    "        out = out.permute(0,2,3,1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "    return nn.BCELoss()(generated, torch.ones(generated.shape).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    real_loss = nn.BCEWithLogitsLoss()(real, torch.ones(real.shape).to(device))\n",
    "    generated_loss =  nn.BCEWithLogitsLoss()(generated, torch.zeros(generated.shape).to(device))\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
    "    loss = torch.mean(torch.abs(real_image - cycled_image))\n",
    "    return LAMBDA * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image, LAMBDA):\n",
    "    loss = torch.mean(torch.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self, lambda_cycle=10):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        self.lambda_cycle=lambda_cycle\n",
    "        self.m_gen = Generator(256,3)\n",
    "        self.p_gen = Generator(256,3)\n",
    "        self.m_disc = Discriminator(256,3)\n",
    "        self.p_disc = Discriminator(256,3)\n",
    "        \n",
    "        self.gen_loss_fn = generator_loss\n",
    "        self.disc_loss_fn = discriminator_loss\n",
    "        self.cycle_loss_fn = calc_cycle_loss\n",
    "        self.identity_loss_fn = identity_loss\n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        real_monet = batch_data[0]\n",
    "        real_photo = batch_data[1]\n",
    "        \n",
    "        # photo to monet back to photo\n",
    "        fake_monet = self.m_gen(real_photo)\n",
    "        cycled_photo = self.p_gen(fake_monet)\n",
    "        \n",
    "        # monet to photo back to monet \n",
    "        fake_photo = self.p_gen(real_monet)\n",
    "        cycled_monet = self.m_gen(fake_photo)\n",
    "        \n",
    "        # generating itself\n",
    "        same_monet = self.m_gen(real_monet)\n",
    "        same_photo = self.p_gen(real_photo)\n",
    "        \n",
    "        # discriminator used to check, inputing real images\n",
    "        disc_real_monet = self.m_disc(real_monet)\n",
    "        disc_real_photo = self.p_disc(real_photo)\n",
    "        \n",
    "        # discriminator used to check, inputing fake images\n",
    "        disc_fake_monet = self.m_disc(fake_monet)\n",
    "        disc_fake_photo = self.p_disc(fake_photo)\n",
    "        \n",
    "        # evaluates generator loss\n",
    "        monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "        photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "        \n",
    "        # evaluates total cycle consistency loss\n",
    "        total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle)\n",
    "        \n",
    "        # evaluates total generator loss\n",
    "        total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "        total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "        \n",
    "        # evaluates discriminator loss\n",
    "        monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "        photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "        \n",
    "        return total_monet_gen_loss, total_photo_gen_loss, monet_disc_loss, photo_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGAN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-4, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    monet_iter = iter(monet_loader)\n",
    "    photo_iter = iter(photo_loader)\n",
    "\n",
    "    for a,b in zip(enumerate(monet_iter), enumerate(photo_iter)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_monet_gen_loss, total_photo_gen_loss, monet_disc_loss, photo_disc_loss = model([a[1].to(device),b[1].to(device)])\n",
    "        total_monet_gen_loss.backward(retain_graph = True)\n",
    "        total_photo_gen_loss.backward(retain_graph = True)\n",
    "        monet_disc_loss.backward()\n",
    "        photo_disc_loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ckdgu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: None\n",
      "epoch: 2\n",
      "loss: None\n",
      "epoch: 3\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    print('epoch:', i)\n",
    "    loss = train()\n",
    "    print('loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dice(), \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = photoset.__getitem__(0).long().numpy()\n",
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generated = model.m_gen(photoset.__getitem__(0).unsqueeze(0).to(device) )\n",
    "\n",
    "    generated = generated.to('cpu').squeeze(0).long().numpy()\n",
    "    plt.imshow(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
